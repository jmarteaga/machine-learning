{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Josh_Arteaga_p1.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pN_s-VjzVAFR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z6UHmLYVhWAN"},"source":["# Project 1: Digit Classification with KNN and Naive Bayes"]},{"cell_type":"markdown","metadata":{"id":"03M_JSg3hWAO"},"source":["In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n","\n","As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n","\n","If you're interested, check out these links related to digit recognition:\n","\n","* Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n","* Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/\n","\n","Finally, if you'd like to get started with Tensorflow, you can read through this tutorial: https://www.tensorflow.org/tutorials/keras/basic_classification. It uses a dataset called \"fashion_mnist\", which is identical in structure to the original digit mnist, but uses images of clothing rather than images of digits. The number of training examples and number of labels is the same. In fact, you can simply replace the code that loads \"fashion_mnist\" with simply \"mnist\" and everything should work fine."]},{"cell_type":"code","metadata":{"id":"iJ9ayCvyhWAP"},"source":["# This tells matplotlib not to try opening a new window for each plot.\n","%matplotlib inline\n","\n","# Import a bunch of libraries.\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import MultipleLocator\n","from sklearn.pipeline import Pipeline\n","from sklearn.datasets import fetch_openml\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.linear_model import LinearRegression\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","\n","# Set the randomizer seed so results are the same each time.\n","np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sO1t0ypThWAR"},"source":["Load the data. Notice that we are splitting the data into training, development, and test. We also have a small subset of the training data called mini_train_data and mini_train_labels that you should use in all the experiments below, unless otherwise noted."]},{"cell_type":"code","metadata":{"id":"3yK9DacchWAS"},"source":["# Load the digit data from https://www.openml.org/d/554 or from default local location '~/scikit_learn_data/...'\n","X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False)\n","\n","\n","# Rescale grayscale values to [0,1].\n","X = X / 255.0\n","\n","# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n","# permutation to X and Y.\n","# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n","shuffle = np.random.permutation(np.arange(X.shape[0]))\n","X, Y = X[shuffle], Y[shuffle]\n","\n","print('data shape: ', X.shape)\n","print('label shape:', Y.shape)\n","\n","# Set some variables to hold test, dev, and training data.\n","test_data, test_labels = X[61000:], Y[61000:]\n","dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n","train_data, train_labels = X[:60000], Y[:60000]\n","mini_train_data, mini_train_labels = X[:1000], Y[:1000]\n","print(mini_train_data.shape)\n","print(mini_train_data[1].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"atc2JpWKhWAV"},"source":["(1) Create a 10x10 grid to visualize 10 examples of each digit. Python hints:\n","\n","- plt.rc() for setting the colormap, for example to black and white\n","- plt.subplot() for creating subplots\n","- plt.imshow() for rendering a matrix\n","- np.array.reshape() for reshaping a 1D feature vector into a 2D matrix (for rendering)"]},{"cell_type":"code","metadata":{"id":"YwYsUIL_VA7i"},"source":["train_labels[0] == str(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"436UeH7JhWAW"},"source":["def P1(num_examples=10):\n","  ### STUDENT START ###\n","  figure, axes = plt.subplots(10, 10)\n","  for x in range(0, 10):\n","    for y in range(0, 10):\n","      for z in range(0, len(train_labels)):\n","        num = z\n","        if train_labels[num] == str(x):\n","          axes[x,y].imshow(train_data[z].reshape(28, 28),cmap='gray_r')\n","          plt.subplots_adjust(bottom=0.2, right=1.5, top=1.5)\n","          axes[x,y].axes.set_frame_on(True)\n","          axes[x,y].set_xticks([], [])\n","          axes[x,y].set_yticks([], [])\n","          break\n","  ### STUDENT END ###\n","\n","P1(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EMQAHr7QhWAX"},"source":["(2) Evaluate a K-Nearest-Neighbors model with k = [1,3,5,7,9] using the mini training set. Report accuracy on the dev set. For k=1, show precision, recall, and F1 for each label. Which is the most difficult digit?\n","\n","- KNeighborsClassifier() for fitting and predicting\n","- classification_report() for producing precision, recall, F1 results"]},{"cell_type":"code","metadata":{"id":"-it5pn8-hWAY"},"source":["def P2(k_values):\n","\n","### STUDENT START ###\n","  for k in k_values:\n","    model = KNeighborsClassifier(n_neighbors=k)\n","    model.fit(mini_train_data, mini_train_labels)\n","    train_predicted_labels = model.predict(dev_data)\n","    print('Results for model k = %d'%k)\n","    print(classification_report(dev_labels,train_predicted_labels))\n","\n","    \n","### STUDENT END ###\n","\n","k_values = [1, 3, 5, 7, 9]\n","P2(k_values)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZc9gzn5hWAZ"},"source":["ANSWER: The most difficult digit to predict is 8."]},{"cell_type":"markdown","metadata":{"id":"7b6YEAzzhWAa"},"source":["(3) Using k=1, report dev set accuracy for the training set sizes below. Also, measure the amount of time needed for prediction with each training size.\n","\n","- time.time() gives a wall clock value you can use for timing operations"]},{"cell_type":"code","metadata":{"id":"6GivK_zaWkT5"},"source":["len(dev_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEpNzDEjhWAa"},"source":["def P3(train_sizes, accuracies):\n","\n","### STUDENT START ###\n","  total_time = []\n","  loop_count = 0\n","  for t in train_sizes:\n","    model = KNeighborsClassifier(n_neighbors=1)\n","    model.fit(train_data[:t], train_labels[:t])\n","    start_time = time.time()\n","    train_predicted_labels = model.predict(dev_data)\n","    end_time = time.time()\n","    total_time.append(end_time - start_time)\n","    accuracies.append(sum(dev_labels == train_predicted_labels)/len(dev_data))\n","    print('The accuracy for ' + str(t)+ ' is '+str(accuracies[loop_count]*100)+' percent and took a total time of '+str(total_time[loop_count])+' seconds.')\n","    loop_count += 1\n","  return(accuracies,total_time)\n","\n","### STUDENT END ###\n","\n","train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n","accuracies = []\n","P3(train_sizes, accuracies)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B56lVsKNhWAc"},"source":["(4) Fit a regression model that predicts accuracy from training size. What does it predict for n=60000? What's wrong with using regression here? Can you apply a transformation that makes the predictions more reasonable?\n","\n","- Remember that the sklearn fit() functions take an input matrix X and output vector Y. So each input example in X is a vector, even if it contains only a single value."]},{"cell_type":"code","metadata":{"id":"4xE_qIJghWAc"},"source":["def P4(sample_data,train_sizes,n):\n","\n","### STUDENT START ###\n","  regr = LinearRegression()\n","  acc_x = np.array(train_sizes)\n","  acc_x = np.reshape(acc_x,(-1,1),)\n","  acc_y = np.array(sample_data)\n","  acc_y = np.reshape(acc_y,(-1,1))\n","  regr.fit(acc_x,acc_y)\n","  arr_n = np.array(n)\n","  arr_n = np.reshape(arr_n,(1,-1))\n","  prediction = regr.predict(arr_n)\n","  return(prediction)\n","\n","### STUDENT END ###\n","n = 60000\n","standard_P4 = P4(accuracies,train_sizes,n)\n","log_P4 = P4(np.log(accuracies),np.log(train_sizes),np.log(n))\n","print(standard_P4)\n","print(np.exp(log_P4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HYYYL9cGhWAe"},"source":["ANSWER: There are a couple of problems here, first 60000 was above our training data so the prediction would be to the right of the \"known universe\" this is often a cause of error.  The other and more glaring problem is that the prediction is for 124% accuracy. Obviously this is not possible.  The data could be transformed using logs which should make it a better predictor."]},{"cell_type":"markdown","metadata":{"id":"geAQJjGRhWAe"},"source":["Fit a 1-NN and output a confusion matrix for the dev data. Use the confusion matrix to identify the most confused pair of digits, and display a few example mistakes.\n","\n","- confusion_matrix() produces a confusion matrix"]},{"cell_type":"code","metadata":{"id":"Bq36xaQohWAf"},"source":["def P5(a):\n","### STUDENT START ###\n","  model = KNeighborsClassifier(n_neighbors=a)\n","  model.fit(mini_train_data, mini_train_labels)\n","  train_predicted_labels = model.predict(dev_data)\n","  conf = confusion_matrix(dev_labels,train_predicted_labels)\n","  print(conf)\n","  plt.imshow(conf, cmap='binary', interpolation='None')\n","  plt.show()\n","  l = 0\n","  b = 0\n","  while (l < 5):\n","    if (train_predicted_labels[b] != dev_labels[b] and dev_labels[b]=='4' and train_predicted_labels[b] == '9'):\n","      print('This was predicted to be a:' + str(train_predicted_labels[b]))\n","      plt.imshow(dev_data[b].reshape(28, 28),cmap='gray_r')\n","      plt.show()\n","      l += 1\n","    b += 1\n","    if b == 1000:\n","      break\n","\n","\n","  ### STUDENT END ### \n","\n","\n","P5(1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b6sBvyKiQVkD"},"source":["ANSWER: The most common error is confusing 4 for a 9.  We also see errors on 9s confused with 7s."]},{"cell_type":"markdown","metadata":{"id":"tgqMKb-hhWAh"},"source":["(6) A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian -- that is, the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n","\n","Implement a simplified Gaussian blur by just using the 8 neighboring pixels: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values. Try applying your blur filter in 3 ways:\n","- preprocess the training data but not the dev data\n","- preprocess the dev data but not the training data\n","- preprocess both training and dev data\n","\n","Note that there are Guassian blur filters available, for example in scipy.ndimage.filters. You're welcome to experiment with those, but you are likely to get the best results with the simplified version I described above."]},{"cell_type":"code","metadata":{"id":"lSKHmHGshWAi"},"source":["def P6(data_set):\n","    \n","### STUDENT START ###\n","  result = np.zeros(data_set.shape)\n","  w = 0.1\n","  for b in range(data_set.shape[0]):\n","    grid = data_set[b].reshape(28, 28)\n","    f = np.zeros((28, 28))\n","    for i in range(28):\n","      for j in range(28):\n","        f[i,j] = grid[i,j] + np.sum(grid[i-1:i+2, j-1:j+2]) / w\n","    result[b] = f.reshape(784,)\n","  return(result)\n","\n","### STUDENT END ###\n","\n","def knn(train_y,test_x):\n","  clf = KNeighborsClassifier()\n","  clf.fit(train_y,mini_train_labels)\n","  predicts = clf.predict(test_x)\n","  print('The accuracy of this method is '+str(sum(predicts == dev_labels)/len(dev_labels)))\n","\n","blur_train_data = P6(mini_train_data)\n","blur_dev_data = P6(dev_data)\n","\n","print('Standard unblurred data')\n","knn(mini_train_data,dev_data)\n","\n","print('Blurring the training data but not the dev data')\n","knn(blur_train_data,dev_data)\n","\n","print('Blurring both the training data and the dev data')\n","knn(blur_train_data,blur_dev_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdZpp9b2hWAj"},"source":["ANSWER: When applying the Gaussian blur to the training and the dev data it significantly lowered the accuracy when blurring training but not dev. However, when the blurring was applied to both sets, the accuracy increased approximately 3 percentage points which crossed the 90% barrier."]},{"cell_type":"markdown","metadata":{"id":"LtgepWfAhWAk"},"source":["(7) Fit a Naive Bayes classifier and report accuracy on the dev data. Remember that Naive Bayes estimates P(feature|label). While sklearn can handle real-valued features, let's start by mapping the pixel values to either 0 or 1. You can do this as a preprocessing step, or with the binarize argument. With binary-valued features, you can use BernoulliNB. Next try mapping the pixel values to 0, 1, or 2, representing white, grey, or black. This mapping requires MultinomialNB. Does the multi-class version improve the results? Why or why not?"]},{"cell_type":"code","metadata":{"id":"eGpH-4IQhWAk"},"source":["def create_bin(data_set,threshold):\n","  bin_data_set = np.zeros(data_set.shape)\n","  for b in range(data_set.shape[0]):\n","    grid = data_set[b].reshape(28, 28)\n","    f = np.zeros((28, 28))\n","    for i in range(28):\n","      for j in range(28):\n","        #f[i,j] = 1\n","        if grid[i,j] < threshold:\n","          f[i,j] = 0\n","        else:\n","          f[i,j] = 1\n","    bin_data_set[b] = f.reshape(784,)\n","  return(bin_data_set)\n","\n","def create_012(data_set,lower_thresh,upper_thresh):\n","  bin_data_set = np.zeros(data_set.shape)\n","  for b in range(data_set.shape[0]):\n","    grid = data_set[b].reshape(28, 28)\n","    f = np.zeros((28, 28))\n","    for i in range(28):\n","      for j in range(28):\n","        #f[i,j] = 1\n","        if grid[i,j] < lower_thresh:\n","          f[i,j] = 0\n","        elif grid[i,j] > upper_thresh:\n","          f[i,j] = 2\n","        else:\n","          f[i,j] = 1\n","    bin_data_set[b] = f.reshape(784,)\n","  return(bin_data_set)\n","\n","def bernoulli(data_set,threshold):\n","  clf = BernoulliNB()\n","  bin_train_data = create_bin(mini_train_data,threshold)\n","  clf.fit(bin_train_data,mini_train_labels)\n","  return(clf.predict(data_set))\n","\n","def multinomial(data_set,lower_thresh,upper_thresh):\n","  clf = MultinomialNB()\n","  mult_train_data = create_012(mini_train_data,lower_thresh,upper_thresh)\n","  clf.fit(mult_train_data,mini_train_labels)\n","  return(clf.predict(data_set))\n","\n","\n","def P7_bern(data_set,threshold):\n","  bin_data_P7 = create_bin(data_set,threshold)\n","  P7_predict = bernoulli(bin_data_P7,threshold)\n","  return(P7_predict)\n","\n","def P7_mult(data_set,lower_thresh,upper_thresh):\n","  mult_data_P7 = create_012(data_set,lower_thresh,upper_thresh)\n","  P7_predict = multinomial(mult_data_P7,lower_thresh,upper_thresh)\n","  return(P7_predict)\n","    \n","### STUDENT END ###\n","\n","bern_predict = P7_bern(dev_data,0.4)\n","print('The BernoulliNB method created '+str(sum(dev_labels != bern_predict))+' errors.')\n","\n","mult_predict = P7_mult(dev_data,0.3,0.6)\n","print('The MultinomialNB method created '+str(sum(dev_labels != mult_predict))+' errors.')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNLrgggohWAm"},"source":["ANSWER: The multinomial classification does not improve errors.  Generally this should be a binary decision on a pixel by pixel basis.  The multinomial likley overfits on the training data."]},{"cell_type":"markdown","metadata":{"id":"PqjbRLg7hWAm"},"source":["(8) Use GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) in a Bernoulli NB model. What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n","\n","- Note that GridSearchCV partitions the training data so the results will be a bit different than if you used the dev data for evaluation."]},{"cell_type":"code","metadata":{"id":"0AvZ-Wp3hWAn"},"source":["def create_bin(data_set):\n","  bin_data_set = np.zeros(data_set.shape)\n","  for b in range(data_set.shape[0]):\n","    grid = data_set[b].reshape(28, 28)\n","    f = np.zeros((28, 28))\n","    for i in range(28):\n","      for j in range(28):\n","        #f[i,j] = 1\n","        if grid[i,j] < 0.4:\n","          f[i,j] = 0\n","        else:\n","          f[i,j] = 1\n","    bin_data_set[b] = f.reshape(784,)\n","  return(bin_data_set)\n","\n","def P8(alphas):\n","\n","### STUDENT START ###\n","  clf = GridSearchCV(BernoulliNB(), param_grid=alphas, refit = True)\n","  return(clf.fit(bin_train_data,mini_train_labels))\n","\n","\n","\n","### STUDENT END ###\n","bin_train_data = create_bin(mini_train_data)\n","bin_dev_data = create_bin(dev_data)\n","#pipeline = Pipeline([('classifier', BernoulliNB())])\n","alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n","nb = P8(alphas)\n","print(nb.cv_results_['mean_test_score'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e52j68ZshWAo"},"source":["print(nb.best_params_)\n","clf_0 = GridSearchCV(BernoulliNB(),param_grid={'alpha':[0.0]}, refit = True)\n","clf_0.fit(bin_train_data,mini_train_labels)\n","pred_clf_0 = clf_0.best_estimator_.predict(bin_dev_data)\n","print(sum(pred_clf_0 != dev_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1yEg9keThWAp"},"source":["*ANSWER*: The best answer for alpha was 0.0001. When running the same process over alpha = 0.0 the classification made 183 errors. This is expected as having alpha set to zero should behave the same as running the BernoulliNB process in previous questions.\n","\n","NOTE: I tried pipelining the data for ages, but could not get the system to process without an error.  This clearly is less efficient."]},{"cell_type":"markdown","metadata":{"id":"B07GDiDdhWAq"},"source":["(9) Try training a model using GuassianNB, which is intended for real-valued features, and evaluate on the dev data. You'll notice that it doesn't work so well. Try to diagnose the problem. You should be able to find a simple fix that returns the accuracy to around the same rate as BernoulliNB. Explain your solution.\n","\n","Hint: examine the parameters estimated by the fit() method, theta\\_ and sigma\\_."]},{"cell_type":"code","metadata":{"id":"gBLbTMWChWAq"},"source":["def P9(test_vars):\n","\n","### STUDENT END ###\n","  clf = GaussianNB(priors=None, var_smoothing=test_vars)\n","  clf_9 = clf.fit(mini_train_data,mini_train_labels)\n","  print(clf_9.get_params)\n","  return(clf_9.predict(dev_data))\n","\n","\n","### STUDENT END ###\n","#some_params = 'sigma_0.2'\n","\n","\n","test_vars = [0.01,0.02,0.05,0.075,0.1,0.5]\n","#gnb = P9()\n","#print(sum(dev_labels != gnb))\n","for i in test_vars:\n","  tt = P9(i)\n","  print(sum(tt != dev_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1SyHTEJohWAt"},"source":["*ANSWER*: In my first attempt, I fit the model on the mini_train_data and predicted on the dev_data.  I did not binarize the data because of the statement that GaussianNB is intended for real value features.  However, the error rate in an uncorrected model was 407 / 1000.\n","\n","To get the mdoel working more closely to the BernoulliNB model, I updated the var_smoothing variable.  This basically allows for a greater variance tolerance than the default."]},{"cell_type":"markdown","metadata":{"id":"dgZMuc1VhWAt"},"source":["(10) Because Naive Bayes is a generative model, we can use the trained model to generate digits. Train a BernoulliNB model and then generate a 10x20 grid with 20 examples of each digit. Because you're using a Bernoulli model, each pixel output will be either 0 or 1. How do the generated digits compare to the training digits?\n","\n","- You can use np.random.rand() to generate random numbers from a uniform distribution\n","- The estimated probability of each pixel is stored in feature\\_log\\_prob\\_. You'll need to use np.exp() to convert a log probability back to a probability."]},{"cell_type":"code","metadata":{"id":"ktii-Mp-hWAu"},"source":["def P10(num_examples):\n","\n","### STUDENT START ###\n","  nb = BernoulliNB()\n","  nb.fit(mini_train_data,mini_train_labels)\n","\n","  fig, axes = plt.subplots(10, num_examples, figsize=(20, 10))\n","  plt.rc('image', cmap='binary')\n","\n","  for i in range(10):\n","    for j in range(num_examples):\n","      log_probs = nb.feature_log_prob_[i]\n","      n = log_probs.shape[0]\n","      r = np.random.rand(n)\n","      d = np.zeros(n)\n","      for k in range(n):\n","        if r[k] < np.exp(log_probs[k]):\n","          d[k] = 1\n","        else:\n","          d[k] = 0\n","      axes[i][j].imshow(d.reshape(28,28), cmap = 'gray_r')\n","      axes[i][j].axis('off')\n","\n","\n","\n","\n","\n","### STUDENT END ###\n","\n","P10(20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SuQd1fTGhWAw"},"source":["ANSWER: Generally the digits look pretty good, but you can tell which digits have a lower general probability throught, like 4.  4 is quite fuzzy while 0 and 1 are clear."]},{"cell_type":"markdown","metadata":{"id":"ksHMg73uhWAx"},"source":["(11) Remember that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior and accuracy.\n","\n","Train a BernoulliNB model with a reasonable alpha value. For each posterior bucket (think of a bin in a histogram), you want to estimate the classifier's accuracy. So for each prediction, find the bucket the maximum posterior belongs to and update the \"correct\" and \"total\" counters.\n","\n","How would you characterize the calibration for the Naive Bayes model?"]},{"cell_type":"code","metadata":{"id":"a1N-St12hWAy"},"source":["def P11(buckets, correct, total):\n","    \n","### STUDENT START ###\n","  nb = BernoulliNB(alpha=0.01)\n","  nb.fit(bin_train_data,mini_train_labels)\n","  predict_nb = nb.predict_proba(bin_dev_data)\n","\n","  for b in range(len(buckets)):\n","    for c in range(0,predict_nb.shape[0]):\n","      if (np.max(predict_nb[c]) >= buckets[b]):\n","        total[b] += 1\n","        if (np.argmax(predict_nb[c]) == np.argmax(dev_labels[c])):\n","          correct[b] += 1\n","\n","\n","\n","\n","                \n","### STUDENT END ###\n","\n","buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n","correct = [0 for i in buckets]\n","total = [0 for i in buckets]\n","\n","P11(buckets, correct, total)\n","print(correct)\n","for i in range(len(buckets)):\n","    accuracy = 0.0\n","    if (total[i] > 0): accuracy = correct[i] / total[i]\n","    print('p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h-4qQsrrhWA1"},"source":["ANSWER: This is a pretty poorly calibrated model.  I feel like there's something I'm still getting wrong here. I've tried numerous variations of the alpha and using binarize versus the binary function written earlier."]},{"cell_type":"markdown","metadata":{"id":"jLDISyh4hWA1"},"source":["(12) EXTRA CREDIT\n","\n","Try designing extra features to see if you can improve the performance of Naive Bayes on the dev set. Here are a few ideas to get you started:\n","- Try summing the pixel values in each row and each column.\n","- Try counting the number of enclosed regions; 8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0.\n","\n","Make sure you comment your code well!"]},{"cell_type":"code","metadata":{"id":"-P7h-t2ThWA2"},"source":["#def P12():\n","\n","### STUDENT START ###\n","\n","\n","### STUDENT END ###\n","\n","#P12()"],"execution_count":null,"outputs":[]}]}